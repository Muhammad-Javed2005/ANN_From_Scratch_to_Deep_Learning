
# ANN From Scratch to Deep Learning 

![Project Type](https://img.shields.io/badge/Type-Study%20Material-blue)
![Python](https://img.shields.io/badge/Python-3.11-blue)
![Deep Learning](https://img.shields.io/badge/Domain-Artificial%20Neural%20Networks-green)
![Libraries](https://img.shields.io/badge/Libraries-NumPy,Matplotlib,Scikit--Learn-yellow)
![License](https://img.shields.io/badge/License-MIT-blue)

---

##  Project Overview

**ANN From Scratch to Deep Learning** is a complete **beginner-to-advanced study repository** developed by **Muhammad Javed**.

This repository focuses on understanding **Artificial Neural Networks (ANN)** from first principles ‚Äî starting from the **Perceptron model** and gradually moving towards **deep learning concepts** like backpropagation, optimizers, regularization, and dropout.

The goal is to **build strong conceptual foundations** by implementing core ideas step-by-step instead of treating neural networks as black boxes.

---

##  Learning Objectives

- Understand how Artificial Neural Networks work internally
- Learn mathematical intuition behind ANN components
- Implement ANN concepts step-by-step in Python
- Understand overfitting and how to prevent it
- Prepare for **ML interviews, exams, and real-world projects**

---

## Tech Stack

- **Language:** Python 3.11  
- **Libraries:**  
  - NumPy  
  - Matplotlib  
  - Scikit-learn  
- **Environment:** Jupyter Notebook  

---

##  Repository Structure

```
ANN_From_Scratch_to_Deep_Learning/
‚îÇ
‚îú‚îÄ‚îÄ 01_Percepton.ipynb              # Basic perceptron model
‚îú‚îÄ‚îÄ 02_Activation_Functions.ipynb   # Sigmoid, ReLU, Tanh, etc.
‚îú‚îÄ‚îÄ 03_Loss_Functions.ipynb         # MSE, Cross-Entropy
‚îú‚îÄ‚îÄ 04_Backpropagation.ipynb        # Gradient descent & backprop
‚îú‚îÄ‚îÄ 05_MLP_Architecture.ipynb       # Multi-Layer Perceptron
‚îú‚îÄ‚îÄ 06_Weight_Initialization.ipynb  # Xavier, He initialization
‚îÇ
‚îú‚îÄ‚îÄ Check_Overfitting.ipynb         # Bias-variance analysis
‚îú‚îÄ‚îÄ Dropout_Layer.ipynb             # Dropout regularization
‚îú‚îÄ‚îÄ Regularization.ipynb            # L1 & L2 regularization
‚îú‚îÄ‚îÄ Optimizer_In_Neural_Nwtwork.ipynb # SGD, Adam, RMSprop
‚îÇ
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ .gitattributes
```

---

##  Notebook Explanations

### 1Ô∏è‚É£ Perceptron
- The simplest neural network unit
- Binary classification logic
- Foundation of ANN

---

### 2Ô∏è‚É£ Activation Functions
- Sigmoid
- ReLU
- Tanh
- Why non-linearity is important

---

### 3Ô∏è‚É£ Loss Functions
- Mean Squared Error (MSE)
- Cross-Entropy Loss
- Error measurement intuition

---

### 4Ô∏è‚É£ Backpropagation
- Chain rule implementation
- Gradient descent
- Weight updates

---

### 5Ô∏è‚É£ MLP Architecture
- Multi-layer neural networks
- Forward & backward pass
- Hidden layers concept

---

### 6Ô∏è‚É£ Weight Initialization
- Why initialization matters
- Vanishing & exploding gradients
- Xavier & He initialization

---

### 7Ô∏è‚É£ Overfitting Check
- Training vs validation error
- Bias-variance tradeoff

---

### 8Ô∏è‚É£ Dropout Layer
- Random neuron deactivation
- Preventing overfitting

---

### 9Ô∏è‚É£ Regularization
- L1 (Lasso)
- L2 (Ridge)
- Model generalization

---

### üîü Optimizers
- Stochastic Gradient Descent (SGD)
- Adam Optimizer
- RMSprop

---

##  How to Use

1. Clone the repository  
```bash
git clone https://github.com/Muhammad-Javed2005/ANN_From_Scratch_to_Deep_Learning.git
```

2. Open Jupyter Notebook  
```bash
jupyter notebook
```

3. Run notebooks sequentially for best learning experience

---

##  Who Is This For?

- Computer Science / Engineering students
- Machine Learning beginners
- Deep Learning learners
- Interview preparation
- Anyone who wants ANN **from scratch**

---

##  Future Improvements

- CNN and RNN implementations
- Full ANN from scratch (no libraries)
- Real-world datasets
- Visualization enhancements

---

##  Author

**Muhammad Javed**  
Computer Engineering Student | Machine Learning Enthusiast  

---

##  Contact

- **GitHub:** https://github.com/Muhammad-Javed2005  
- **LinkedIn:** https://www.linkedin.com/in/muhammad-javed-24b262369/  
- **Email:** muhammadjaved.tech5@gmail.com  

---

‚≠ê If you find this repository helpful, please consider giving it a star!

